20,マルチスレッドのウェブサーバ構築から

TCPは情報がとあるサーバから別のサーバへどう到達するかの詳細を記述するものの、
その情報がなんなのかは指定しない、より低レベルのプロトコル。HTTPはリクエストとレスポンスの中身を定義することでTCPの上に成り立っている。
技術的にはHTTPを他のプロトコルとともに使用することが出来るが、大抵の場合はHTTPはTCPの上にデータを送信する。
TCPとHTTPのリクエストとレスポンスの生のバイトを取り扱う。


TcpListener::bind("127.0.0.1:7878").unwrap();

std::net::TcpListenerを使うことにより、アドレス127.0.0.1:7878でTCP接続をリッスン出来る。
アドレス内でコロンの前の区域は自分のコンピュータを表すIPアドレスで、7878はポート。
このポートを選んだ理由として、HTTPは通常このポートで受け入れられることと7878は電話でrustと入力されるから。

この筋書きでのbind関数は新しいTcpListenerインスタンスを返すという点でnew関数のような働きをする。
この関数がbindと呼ばれている理由は、ネットワークにおいてリッスンすべきポートに接続することは、
ポートに束縛することとして知られている。

bind関数はResult<T,E>を返し、束縛が失敗することもあることを示している。
例えばポート80に接続するには管理者権限が必要なので、管理者にならずにポート80に接続しようとしたらうまくいかない。
また、自分のプログラムを2つ同時に立ち上げて2つのプログラムが同じポートをリッスンしたら、束縛は機能しない。
学習目的のためだけに基本的なサーバを記述しているので、この類のエラーを扱う心配をせず、unwrapを使用してエラーが発生したらプログラムを停止する。

TcpListenerのincomingメソッドは一連のストリームを与えるイテレータを返す。具体的には型TcpStreamのストリーム。
単独のストリームがクライアント・サーバ間の開かれた接続を表す。
せず奥は、クライアントがサーバに接続し、サーバがレスポンスを生成し、サーバが接続を閉じるというリクエストとレスポンス全体の過程の名前。
そのため、TcpStreamは自身を読み取ってクライアントが送信したことを確認し、それからレスポンスをストリームに記述させてくれる。
総括すると、このforループでは各接続を順番に処理し、自分たちが扱えるように一連のストリームを生成している。

まず最初にストリームはunwrapを呼び出して、ストリームにエラーが有った場合はプログラムを停止することから始めている。
エラーがなければプログラムはメッセージを出力する。
クライアントがサーバーに接続する際にincomingメソッドからエラーを受け取る可能性がある理由は、実際には接続を走査していないから。
代わりに接続の試行を走査している。接続は多くの理由で失敗する可能性があり、そのうちの多くはOS特有。
例を上げれば多くのOSにはサポートできる同時に開いた接続数に上限がある。開かれた接続の一部が閉じられるまでその上限数を超えた接続の試行はエラーになる。

現在の実装ではサーバがデータを返してこないのでブラウザではエラーが出るが、メッセージは出ているので接続ができていることを確認できる。
一回のブラウザリクエストで複数のメッセージが出力されるのは、ブラウザがサーバに何度も接続を試みているという可能性があるが、理由は定かではない。

streamがスコープを抜け、ループの最後でドロップされると、接続はdrop実装の一部として閉じられる。
ブラウザは再試行することで閉じられた接続を扱うことがある。問題が一時的なものである可能性があるため。
重要な要素はTCP接続へのハンドルを得ることに成功したということ。


ブラウザからリクエストを読み取る機能を実装する。
まず接続を得て、それから接続に対してなんらかの行動を行う責任を分離するために、接続を処理する新しい関数を作成する。
新しいhandle_connection関数において、TCPストリームからデータを読み取り、ブラウザからデータが送られていることを確認できるように端末に出力させる。

std::io::preludeをスコープに導入して、ストリームから読み書きさせてくれる特定のトレイトにアクセスできるようにしている。
先程は接続を確立したというメッセージを出力していたが、今回はhandle_connection関数を呼び出し、streamを渡している。

handle_connection関数においてstream引数を可変にしたが、理由はTcpStreamインスタンスが内部で返すデータを追いかけているから。
要求した以上のデータを読み取り、次回データを要求したときのためにそのデータを保存する可能性がある。
故に、内部の状態が変化する可能性があるので、mutにする必要がある。

次にストリームから読み取りを2つの手順で行っていく。まずスタックに読み取ったデータを保持するbufferを宣言する。
今回はバッファーのサイズを1024バイトにした。今回の目的を達成するには十分な大きさ。
このバッファーをstream.readに渡し、これがTcpStreamからバイトを読み取ってバッファーに置く。

2番めにバッファーのバイトを文字列に変換し、その文字列を出力する。
String::from_utf8_lossy関数は&[u8]を取り、Stringを生成する。名前のlossyの部分は、
無効なUTF-8シーケンスに遭遇したときの関数の振る舞いを示唆している。
無効なシーケンスをU+FFFD REPLACEMENT CHARACTERで置き換える。
バッファーとして1024バイトの領域を用意しているが、リクエストデータは1024バイト存在しないことがほとんどなので、
変数bufferの後ろ部分が産められないまま放置されるため、置換された文字が表示されることがある。


今回の実行結果はこんな感じになる。

Request: GET / HTTP/1.1
Host: 127.0.0.1:7878
Connection: keep-alive
sec-ch-ua: " Not;A Brand";v="99", "Google Chrome";v="91", "Chromium";v="91"
sec-ch-ua-mobile: ?0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: none
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Accept-Encoding: gzip, deflate, br
Accept-Language: ja,en-US;q=0.9,en;q=0.8


HTTPはテキストベースのプロトコルで、1つの要求は以下のフォーマットに則っている。
Method Request-URI HTTP-Version CRLF
headers CRLF
message-body

一行目はクライアントが要求しているものが何なのかについての情報を保持するリクエスト行。
リクエスト行の最初の部分は使用されているGETやPOSTなどのメソッドを示し、
これはどのようにクライアントがこの要求を行っているかを記述する。クライアントはGETリクエストを使用している。

リクエスト業の次の部分は/で、これはクライアントが要求しているURI(Uniform Resource Identifier)を示している。
URIはほぼURL(Uniform Resource Locator)と同じだが、完全に同じではない。
HTTPの規格はURIという用語を使用している。

※URLはインターネット上に存在するファイルの場所を示すもので、Web上の住所に当たる。
　URIはインターネット上に素材するあらゆるファイルを識別する総称。URLはURIの一部。
　Web上の名前にあたるURNと合わせてURIと呼ばれている。

最後の部分はクライアントが使用しているHTTPのバージョンで、それからリクエスト行はCRLFで終了する。
CRLFにより、リクエスト行がリクエストデータの残りと区別される。CRLFを出力すると、\r\nではなく新しい行が開始されることに注意。

今回のリクエストは、
GETがメソッド、/が要求URI、HTTP/1.1がバージョンになっている。


クライアントのリクエストに対する返答としてデータの送信を実装していく。
レスポンスは以下のようなフォーマットになっている。

HTTP-Version Status-Code Reason-Phrase CRLF
headers CRLF
message-body

最初の行はレスポンスで使用されるHTTPバージョン、リクエストの結果を要約する数値ステータスコード。
そしてステータスコードのテキスト記述を提供する理由句を含むステータス行。
CRLFシーケンスのあとに任意のヘッダ、別のCRLFシーケンス、そしてレスポンスの本体が続く。

例えばHTTPバージョン1.1、ステータスコード200、OKフレーズ、ヘッダと本体なしのレスポンスは以下の通り。
HTTP/1.1 200 OK\r\n\r\n

ステータスコード200は一般的な成功のレスポンス。
これを成功したリクエストの返答としてストリームに書き込んでいく。

成功したメッセージのデータを保持するresponse変数を定義していて、responseに対してas_bytesを呼び出し、
文字列データをバイトに変換する。streamのwriteメソッドは&[u8]を取り、接続に直接そのバイトを送信する。
write処理は失敗することもあるので、以前のようにエラーの結果にはunwrapを使用する。
実際のアプリではエラー処理をきちんと追加してね。
最後にflush関数はバイトが全て接続に書き込まれるまでプログラムが継続するのを防ぐ。
TcpStreamは内部にバッファーを保持して、もととなるOSへの呼び出しを最小化する。


次はsrcの親ディレクトリに置いておいたhello.htmlをレスポンスとして返すようにしていく。
まずは標準ライブラリのFileをスコープに導入し、ファイルを開いて中身を読み込んでいる。
次に、format!でファイルの中身を成功したレスポンスの本体として追記している。

現時点ではbuffer内のリクエストデータは無視して、無条件でHTMLファイルの中身を送り返しているだけ。
これはつまり、ブラウザで127.0.0.1:7878/somethingをリクエストしても、同じHTMLレスポンスが得られるということ。
次はリクエストに基づいてレスポンスをカスタマイズし、/への合法なリクエストに対してのみHTMLファイルを送り返すようにしていく。

まず/リクエストに対応するデータをget変数に
let get = b"GET / HTTP/1.1\r\n";
とハードコードしている。生のバイトをバッファーに読み込んでいるので、b""というバイト文字列記法を中身のデータの先頭に追記することで、
getをバイト文字列に変換している。そしてbufferがgetのバイトから始まっているかを確認している。
もしそうならば/への合法的なリクエストを受け取ったことを意味し、これがHTMLファイルの中身を返すifブロックで扱う成功した場合になる。

bufferがgetのバイトで始まらないのであれば他のリクエストに受け取ったことになり、elseブロックでの処理に入る。


現状ではサーバはリクエストを順番に処理している。つまり、最初の接続が処理し終わるまで2番めの接続は処理しない。
サーバの受け付けるリクエストの量が増えるほど、この連続的な実行は最適ではなくなる。
サーバが処理するのに長い時間がかかるリクエストを受け付けたら、このリクエスト自体は迅速に処理できても、
続くリクエストは長いリクエストが完了するまで待たなければならなくなる。

use std::thread;
use std::time::Duration;
// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        thread::sleep(Duration::from_secs(5));
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };

    // --snip--
}

例えばこのコードで/sleepに接続しながら/に接続しようとすると、/が待たされるのを確認できる。

この問題を解決するために、多くのリクエストが遅いリクエストの背後に回ってしまうのを回避するようにウェブサーバが動く方法を変える方法は複数ある。
ここではスレッドプールを実装する。

スレッドプールは待機し、タスクを処理する準備のできた一塊の大量に生成されたスレッド。
プログラムが新しいタスクを受け取ったら、プールのスレッドのどれかをタスクにあてがい、そのスレッドがそのタスクを処理する。
プールの残りのスレッドは最初のスレッドが処理中にやってくる他のあらゆるタスクを扱うために利用可能。
最初のスレッドがタスクの処理を完了したら、アイドル状態のスレッドプールに戻り、新しいタスクを処理する準備ができる。
スレッドプールにより、並行で接続を処理でき、サーバのスループットを向上させる。

プール内のスレッド数は小さい数字に制限し、DoS攻撃から保護する。リクエストが来るたびに新しいスレッドを生成させると、
大量のリクエストをサーバに送り、サーバのリソースを使い尽くしリクエストの処理を停止に追い込むことができてしまう。

無制限にスレッドを大量生産するのではなく、プールに固定された数のスレッドを待機させる。リクエストが来るたびに、
処理するためにプールに送られる。プールはやってくるリクエストのキューを管理する。
プールの各スレッドがこのキューからリクエストを取り出し、リクエストを処理し、別のリクエストをキューに要求する。
この設計により、Nリクエストを並行して処理でき、ここで言うNはスレッド数のこと。
各スレッドが実行に時間のかかるリクエストに応答していたら、続くリクエストはキュー内で待機させられることもあるが、
その地点に到達する前に扱える時間のかかるリクエスト数を増加させれば良い。
この他にWebサーバのスループットを向上させる方法としては、fork/joinモデルと、シングルスレッドの非同期I/Oモデルが挙げられる。


まずはリクエストが来るたびにスレッドを立ち上げるようにし、次にThreadPoolという架空の構造体を作ってコンパイルエラーを見ながら実装する方向で進めていく。
ThreadPoolにexecuteメソッドをクロージャを引数として受け取るように定義する。
クロージャを受け取るときにはFn,FnMut,FnOnceの3つから選べるが、
最終的には標準ライブラリのthread::spawn実装に似たことをするのがわかっているので、これを参考に作っていく。

pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T + Send + 'static,
        T: Send + 'static

F型引数がここで関心のあるもの。T型引数は戻り値と関係があり、関心はない。
spawnはFのトレイト境界としてFnOnceを使用していることが確認できる。
executeで得た引数をspawnに渡すので、今回欲しい型もこれになるであろうことがわかる。
また、リクエストを実行するスレッドはそのリクエストのクロージャを一回だけ実行し、FnOnceのOnceに合致している。

F型引数にトレイト境界のSendとライフタイム境界の'staticもあり、この状況では有用。
あるスレッドから別のスレッドにクロージャを移動するのにSendが必要で、
スレッドの実行にどれくらいかかるのかわからないので'staticも必要。
なので実際にexecuteメソッドの実装に移っていく。

newでスレッド数を検査し、0より大きいsizeを渡されたらエラーになるようにする。

spawn関数はJoinHandle<T>を返し、ここでTはクロージャが返す型になる。
今回の状況ではスレッドプールに渡すクロージャは接続を扱い、何も返さないので、
Tはユニット型()になる。

ThreadPoolの定義を変更して、thread::JoinHandle<()>インスタンスのベクタを保持し、
sizeキャパシティのベクタを初期化子、スレッドを生成する何らかのコードを実行するforループを設定し、
それらを含むThreadPoolインスタンスを返す。

ライブラリクレート内でstd::threadをスコープに導入した。ThreadPoolのベクタの要素の型として、thread::JoinHandleを使用しているため。
一旦合法なサイズを受け取ったら、ThreadPoolはsize個の要素を保持できる新しいベクタを生成する。
with_capacity関数はVec::newと同じ作業をしつつ、ベクタに予めスペースを確保しているという重要な違いがある。
このメモリ確保を前もってしておくとVec::newよりも少しだけ効率的になる。
Vec::newは要素が挿入されるにつれて自分のサイズを変更するため。

標準ライブラリはスレッドを生成する手段としてthread::spawnを提供し、
thread::spawnは生成されるとすぐに生成されるとすぐにスレッドが実行すべき何らかのコードを得ることを予期する。
しかし今回の使い方では、スレッドを生成して、後ほど送信するコードを待機して欲しい。
標準ライブラリのスレッドの実装ではそうすることができないので、手動で実装しなければならない。
この振る舞いを管理するスレッドとThreadPool間に新しいデータ構造を導入することでこの振る舞いを実装する。
このデータ構造をWorkerと呼び、プール実装では一般的な用語。

スレッドプールにJoinHandle<()>インスタンスのベクタを格納する代わりにWorker構造体のインスタンスを格納する。
各Workerが単独のJoinHandle<()>インスタンスを格納し、そしてWorkerに実行するコードのクロージャを取り、
既に走っているスレッドに実行してもらうために送信するメソッドを実装する。
ログを取ったりデバッグする際にプールの異なるワーカーを区別できるように、各ワーカーにidも付与する。

外部のコードはThreadPool内でWorker構造体を使用していることに関する実装の詳細を知る必要はないため、
Worker構造体とそのnew関数は非公開にしている。
Worker::new関数は与えたidを使用し、空のクロージャを使って新しいスレッドを立ち上げることで生成されるJoinHandle<()>インスタンスを格納する。

現状ではexecuteメソッドで実行したいクロージャを得ているが、ThreadPoolの生成中、
Workerそれぞれを生成する際に実行するクロージャをthread::spawnに与える必要がある。
作ったばかりのWorker構造体にThreadPoolが保持するキューから実行するコードをフェッチして、そのコードをスレッドが実行できるように送信させる。

receiverを複数のWorkerインスタンスに渡そうとしているので、これはチャンネルの実装である、
複数の生成者・単独の消費者に違反するので動作しない。
チャンネルの消費側をクローンするだけではこのコードを修正することはできない。
例えできたとしても使用したいテクニックではない。代わりに全ワーカー間で単独のreceiverを共有することによってスレッド間に仕事を分配したい。
また、チャンネルキューから仕事を取り出すことはreceiverを可変化することに関連するので、
スレッドにはreceiverを共有して変更する安全な方法が必要。これを保証しなければ競合状態に陥る可能性がある。

スレッド安全なスマートポインタとしてArc<Mutex<T>>を以前に説明した。
Arc型は複数のワーカーに受信者を所有させ、Mutexにより一度に受信者が一つの仕事を1つのワーカーが受け取ることを保証する。

executeで得たクロージャを使用して新しいJobインスタンスを生成したあと、その仕事をチャンネルの送信側に送信している。
送信が失敗したときのためにsendに対してunwrapを呼び出している。
これは例えば全スレッドの実行を停止させるなど、受信側が新しいメッセージを受け取るのをやめてしまったときに起こる可能性がある。
現時点ではスレッドの実行を止めることはできない。スレッドはプールが存在する限り実行し続ける。
unwrapを使用している理由は失敗する場合が起こらないとわかっているからだが、コンパイラにはわからない。

とはいえこれで完成ではない。ワーカー内でthread::spawnに渡されているクロージャは、チャンネルの受信側を参照しているだけ。
その代わりにクロージャには永遠にループし、チャンネルの受信側に仕事を要求し、仕事を得たらその仕事を実装してもらう必要がある。

まずreceiverに対してlockを呼び出してミューテックスを獲得し、それからunwrapを呼び出して、エラーの際にはパニックする。
ロックの獲得は、ミューテックスが毒された状態なら失敗する可能性がある。
これは他のどれかのスレッドがロックを保持している間に解放するのではなく、パニックした場合に起きうる。
この場合ではunwrapを呼び出してこのスレッドをパニックさせるのは、正当な行動になっている。

ミューテックスのロックを獲得できたら、recvを呼び出してチャンネルからJobを受け取る。最後のunwrapもここであらゆるエラーを超えていき、
これはチャンネルの送信側を保持するスレッドが閉じた場合に発生する可能性があり、受信側が閉じた場合にsendメソッドがErrを返すのと似ている。

recvの呼び出しはブロックを行うので、仕事がなければ現在のスレッドは仕事が利用可能になるまで待機する。
Mutex<T>により、ただ1つのWorkerスレッドのみが一度に仕事の要求を試みることを保証する。


現在の状態では(*job)();の部分がエラーになっている。

Box<T>に格納されたFnOnceクロージャを呼び出すためには呼び出す際にクロージャがselfの所有権を奪うので、
クロージャは自身をBox<T>からムーブする必要がある。
一般的にRustはBox<T>から値をムーブすることを許可しない。コンパイラにはBox<T>の内部の値がどれほどの大きさなのか見当がつかないため。
記法self: Box<Self>を使用するメソッドを書くことができ、これによりメソッドはBox<T>に格納されたSelf値の所有権を奪うことが出来る。
しかしながら今回は使えない。クロージャが呼び出された際に振る舞いを実装するRustの一部はself: Box<Self>を使用して実装されていないため。

self: Box<Self>でBox<T>の内部の値の所有権を奪うことが出来ることをコンパイラに明示的に教えてあげることによってこの問題を回避する。
シグニチャにself: Box<Self>を使用するcall_boxというメソッドのある新しいトレイトFnBoxを定義すること、
FnOnce()を実装する任意の型にたいしてFnBoxを定義すること、型エイリアスを新しいトレイトを使用するように変更すること、
Workerをcall_boxメソッドを使用するようにしていく。

最初にFnBoxという新しいトレイトを作成する。このトレイトにはcall_boxという1つのメソッドがあり、
これはself: Box<Self>を取ってselfの所有権を奪い、Box<T>から値をムーブする点を除いて他のFn*トレイトのcallメソッドと類似している。
次にFnOnce()トレイトを実装する任意の型Fに対してFnBoxトレイトを実装する。
実質的にこれはあらゆるFnOnce()クロージャがcall_boxメソッドを使用できることを意味する。
call_boxの実装は(*self)()を使用してBox<T>からクロージャをムーブし、クロージャを呼び出す。

これでJob型エイリアスには、新しいトレイトのFnBoxを実装する何かのBoxである必要が出てきた。
これによりクロージャを直接呼び出す代わりに、Job値を得たときにWorkerのcall_boxを使える。
任意のFnOnce()クロージャに対してFnBoxトレイトを実装することは、チャンネルに送信する実際の値は何も変えなくてもいいことを意味する。


どこでミスをしたかわからないが動かない。

Worker 0 got a job; executing.
thread '<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: RecvError', src\lib.rs:70:59
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
thread '<unnamed>' panicked at 'thread 'called `Result::unwrap()` on an `Err` value: "PoisonError { inner: .. }"<unnamed>', ' panicked at 'src\lib.rscalled `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: "指定されたファイルが見つかりません。" }:', 70src\bin\main.rs::4340
:41thread '
<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: "PoisonError { inner: .. }"', src\lib.rs:70:43

エラーメッセージをきちんと出すようにしたところ、lockに失敗しているみたい。解放のところがうまくできてないのかな？
一応このあとの部分で全コードを上げているところがあるので、解決はそこのコピペで行う。


現状では現在のコードでは片付けを何も行っていない。
現在ではctrl+cで停止しているが、この方法ではリクエストの処理中であっても他のスレッドも停止する。
そこで閉じる前にプールの各スレッドに対してjoinを呼び出すDropトレイトを自走する。
そしてスレッドに新しい受付を停止し、終了するように教える方法を実装する。

まずスレッドプールworkersそれぞれを走査する。selfは可変参照であり、workerを可変化できる必要もあるので、
これには&mutを使用する。ワーカーそれぞれに対して、特定のワーカーを終了する旨のメッセージを出力し、
それからjoinをワーカースレッドに対して呼び出している。
joinの呼び出しが失敗したら、unwrapを使用してRustをパニックさせ、正常でないシャットダウンに移行する。

今の状態の実装では、各workerの可変参照しかなく、joinは引数の所有権を奪うためにjoinを呼び出せないというエラーが出る。
この問題を解決するために、joinがスレッドを消費できるように、threadを所有するWorkerインスタンスからスレッドをムーブする必要がある。
Workerが代わりにOption<thread::JoinHandle<()>>を保持していれば、Optionに対してtakeメソッドを呼びだし、
Some列挙子から値をむーぶし、その場所にNone列挙子を残すことが出来る。
つまり、実行中のWorkerにはthreadにSome列挙子があり、Workerを片付けたいときにはワーカーが実行するスレッドがないようにSomeをNoneで置き換える。

以前述べたように、OptionのtakeメソッドはSome列挙子を取り出し、その箇所にNoneを残す。
if letを使用してSomeを分配し、スレッドを得ている。そしてスレッドに対してjoinを呼び出す。
ワーカーのスレッドが既にNoneならワーカーはスレッドを既に片付け済みであることがわかるので、その場合には何も起きない。

現状ではWorkerインスタンスのスレッドで実行されるクロージャのロジックが問題になってくる。
joinを呼び出しているが、仕事を求めて永遠にloopするのでスレッドが終了しない。
この問題を修正するために、スレッドが実行すべきJobか、リッスンをやめて無限ループを抜ける通知をリッスンするように変更する。

今ではワーカーを2回走査している。各ワーカーにTerminateメッセージを送信するために一回と、
各ワーカースレッドにjoinを呼び出すために一回。メッセージ送信とjoinを同じループで即座に行おうとすると、
現在の繰り返しのワーカーがチャンネルからメッセージを受け取っているものであるかを保証できなくなってしまう。

単独のループで各ワーカーを走査すると、最初の繰り返しでチャンネルに停止メッセージが送信され、
joinが最初のワーカースレッドで呼び出される。その最初のワーカーが現在リクエストの処理で忙しければ、
二番目のワーカーがチャンネルから停止メッセージを受け取り、閉じる。
最初のワーカーの終了待ちをしたままだが、二番目のスレッドが停止メッセージを拾ってしまったので、終了することは絶対になく、デッドロックになる。

このような状態に陥るのを回避するために、1つ目のループでまずチャンネルに対して全てのTerminateメッセージを送信する。
そして別のループで全スレッドのjoinを待つ。一旦停止メッセージを受け取ったら、各ワーカーはチャンネルからのリクエスト受付をやめる。
故に、存在するワーカーと同じ数だけ停止メッセージを送れば、joinがスレッドに対して呼び出される前に、
停止メッセージを各ワーカーが受け取ると確信できる。


全コードコピーしてもコンパイルエラーで通らなかった。
正直Rustでウェブサーバーやるきないのでここでやめておく。
付録の方に入ったほうが時間を無駄にしないと思うので。


付録A：キーワード
https://doc.rust-jp.rs/book-ja/appendix-01-keywords.html
このリンクに載っている語句のリストは、現在あるいは将来Rust言語によって使用されるために予約されているキーワード。
これらの単語は識別子として使うことができない。
識別子には、関数名・変数名・引数名・構造体のフィールド名・モジュール名・クレート名・定数名
マクロ名・静的な値の名前・属性名・型名・トレイト名・ライフタイム名などがある。
ただし生識別子のところで議論する生識別子は例外になる。

生識別子とは、普段は使うことが許されないキーワードを使わせている構文。
生識別子は、キーワードの前に#rをおいて使うことが出来る。

matchはキーワードになっているが、引数で渡した文字が文字列に存在しているかを調べるmatch関数を作ろうとすると、
error: expected identifier, found keyword `match`
 --> src/main.rs:4:4
  |
4 | fn match(needle: &str, haystack: &str) -> bool {
  |    ^^^^^ expected identifier, found keyword

  のようなコンパイルエラーを出す。

fn r#match(needle: &str, haystack: &str) -> bool {
    haystack.contains(needle)
}

fn main() {
    assert!(r#match("foo", "foobar"));
}

このようにr#matchとすることにより、予約されているキーワードを使った関数を使うことが出来る。
注意すべきなのは、宣言するときだけでなく使用するときにもr#を付ける必要があること。


付録B：演算子と記号
https://doc.rust-jp.rs/book-ja/appendix-02-operators.html
演算子やパス、ジェネリクス、トレイト境界、マクロ、属性、コメント、タプル、かっこの文脈で現れる他の記号を含むRustの記法の用語集。
演算子をオーバーロード可能かどうかと、オーバーロード可能であるならばオーバーロドするために使用するトレイトが列挙されている。


付録C：導出可能なトレイト
これまでいろいろな場所でderive属性について議論してきた。これは構造体やenum定義に適用できる。
derive属性は、derive記法で注釈した型に対して独自の既定の実装でトレイトを実装するコードを生成する。

derive属性が提供する以外の異なるふるまいが欲しいなら、それらを手動で実装する方法の詳細について、
各トレイトの標準ライブラリのドキュメンテーションを調べてほしい。
標準ライブラリで定義されている残りのトレイトはderiveで自分の型に実装することはできない。
これらのトレイトには知覚できるほどの既定の振る舞いはないので、自分が達成しようとしていることに対して、自分が責任を持って実装するべき。

導出できないトレイトの例としてDisplayが挙げられ、こはエンドユーザ向けのフォーマットを扱う。
型のどの部分をエンドユーザは見ることができるべきか、型を表示する適切な方法とは？そしてどんな形式のデータがエンドユーザにとって最も関係があるのか。
これらはRustコンパイラが推論できる範囲ではないため、適切な既定動作を提供していない。


・プログラマ用の出力のDebug
Debugトレイトにより、フォーマット文字列でのデバッグ整形が可能になり、{}プレースホルダー内に:?を追記することで表す。
Debugトレイトにより、デバッグ目的で型のインスタンスを出力できるようになるので、自分や型を使用する他のプログラマが、
プログラムの実行の特定の箇所でインスタンスを調べることができるようになる。

Debugトレイトは例えばassert_eq!マクロを使用する際などに必要になる。
このマクロは等価アサートが失敗したら、引数として与えられたインスタンスの値を出力する。

・等価比較のためのPartialEqとEq
PartialEqトレイトにより、型のインスタンスを比較して等価性をチェックできる。
これにより==と!=演算子の使用を可能にする。

PartialEqを導出すると、eqメソッドを実装する。構造体にPartialEqを導出すると、
全フィールドが等しいときのみ2つのインスタンスは等価になり、いずれかのフィールドが等価でなければ、インスタンスは等価でなくなる。
enumに導出すると、各列挙子は自身には等価だが、他の列挙子には等価ではない。
PartialEqトレイトは例えばassert_eq!マクロを使用する際に必要になる。
これは等価性のためにある型2つのインスタンスを比較できる必要がある。

Eqトレイトにはメソッドは存在しない。その目的は注釈された型の全値に対して、
値が自身と等しいことを通知すること。EqトレイトはPartialEqを実装する全ての型がEqを実装できるわけではないが、
PartialEqも実装する型に対してのみ適用できる。一例として浮動小数点数型が挙げられる。
浮動小数点数の実装により、NaN(非数字)値の2つのインスタンスはお互いに等価ではないことが宣言される。

Eqが必要になる一例が、HashMap<K, V>のキーで、HashMap<K, V>が2つのキーが同じであると判定できる。


・値を複製するCloneとCopy
Cloneトレイトにより値のディープコピーを明示的に行うことができ、複製のプロセスは任意のコードを実行し、
ヒープデータをコピーすることに関係がある可能性がある。Cloneについて詳しくは以前の内容を参照。
Cloneを導出すると、cloneメソッドを実装し、これは型全体に実装されると型の各部品に対してcloneを呼び出す。
要するにCloneを導出するには、型のフィールドと値全部もCloneを実装していなければならないということ。

Cloneが必要になる例はスライスに対してto_vecメソッドを呼び出すこと。スライスは含んでいる型のインスタンスの所有権を持たないが、
to_vecで返されるベクタはそのインスタンスを所有する必要があるので。to_vecは各要素に対してcloneを呼び出す。
故にスライスに格納される型はCloneを実装しなければならない。

Copyトレイトによって、スタックに格納されたビットをコピーするだけで値を複製できる。
ここには任意のコードは必要ない。Copyについても以前の内容を参照。

Copyトレイトは、プログラマがメソッドをオーバーロードし、任意コードが実行されないという前提を侵害することを妨げるメソッドは何も定義しない。
そのため、全プログラマは値のコピーは非常に高速であることを前提にすることができる。
部品全てがCopyを実装する任意の型に対してCopyを導出することができる。
Cloneも実装する型に対してのみ、Copyトレイトを適用することができる。なぜならCopyを実装する型にはCopyと同じ作業を行うCloneの些末な実装があるから。

Copyトレイトは稀にしか必要にならない。Copyを実装する型では最適化が利用可能になる。
つまり、cloneを呼び出す必要がなくなり、コードがより簡潔になるということ。
Copyで可能なこと全てがCloneでも達成可能だが、コードがより遅い可能性や、cloneを使用しなければならない箇所があったりする。


・値を固定サイズの値にマップするHash
Hashトレイトにより、任意のサイズの型のインスタンスを取り、そのインスタンスをハッシュ関数で固定サイズの値にマップできる。
Hashを導出すると、hashメソッドを実装する。
hashの導出された実装は、型の各部品に対して呼び出したhashの結果を組み合わせる。
つまり、Hashを導出するには全フィールドと値もHashを実装しなければならないということ。
Hashが必要になる例は、HashMap<K, V>にキーを格納し、データを効率的に格納すること。


・既定値のためのDefault
Defaultトレイトにより、型に対して既定値を生成できる。Defaultを導出すると、default関数を実装する。
default関数の導出された実装は、型の各部品に対してdefault関数を呼び出す。
つまり、Defaultを導出するには型の全フィールドと値もDefaultを実装しなければならないということ。

Default::default関数は、構造体更新記法と組み合わせてよく使用される。
構造体のいくつかのフィールドをカスタマイズし、それから..Default::default()を使用して、
残りのフィールドに対して既定値をセットし使用することができる。

例えばDefaultトレイトはOption<T>インスタンスに対してメソッドunwrap_or_defaultを使用するときに必要になる。
Option<T>がNoneならばメソッドunwrap_or_defaultはOption<T>に格納された型Tに対してDefault::defaultの結果を返す。