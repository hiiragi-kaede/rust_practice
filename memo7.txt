20,マルチスレッドのウェブサーバ構築から

TCPは情報がとあるサーバから別のサーバへどう到達するかの詳細を記述するものの、
その情報がなんなのかは指定しない、より低レベルのプロトコル。HTTPはリクエストとレスポンスの中身を定義することでTCPの上に成り立っている。
技術的にはHTTPを他のプロトコルとともに使用することが出来るが、大抵の場合はHTTPはTCPの上にデータを送信する。
TCPとHTTPのリクエストとレスポンスの生のバイトを取り扱う。


TcpListener::bind("127.0.0.1:7878").unwrap();

std::net::TcpListenerを使うことにより、アドレス127.0.0.1:7878でTCP接続をリッスン出来る。
アドレス内でコロンの前の区域は自分のコンピュータを表すIPアドレスで、7878はポート。
このポートを選んだ理由として、HTTPは通常このポートで受け入れられることと7878は電話でrustと入力されるから。

この筋書きでのbind関数は新しいTcpListenerインスタンスを返すという点でnew関数のような働きをする。
この関数がbindと呼ばれている理由は、ネットワークにおいてリッスンすべきポートに接続することは、
ポートに束縛することとして知られている。

bind関数はResult<T,E>を返し、束縛が失敗することもあることを示している。
例えばポート80に接続するには管理者権限が必要なので、管理者にならずにポート80に接続しようとしたらうまくいかない。
また、自分のプログラムを2つ同時に立ち上げて2つのプログラムが同じポートをリッスンしたら、束縛は機能しない。
学習目的のためだけに基本的なサーバを記述しているので、この類のエラーを扱う心配をせず、unwrapを使用してエラーが発生したらプログラムを停止する。

TcpListenerのincomingメソッドは一連のストリームを与えるイテレータを返す。具体的には型TcpStreamのストリーム。
単独のストリームがクライアント・サーバ間の開かれた接続を表す。
せず奥は、クライアントがサーバに接続し、サーバがレスポンスを生成し、サーバが接続を閉じるというリクエストとレスポンス全体の過程の名前。
そのため、TcpStreamは自身を読み取ってクライアントが送信したことを確認し、それからレスポンスをストリームに記述させてくれる。
総括すると、このforループでは各接続を順番に処理し、自分たちが扱えるように一連のストリームを生成している。

まず最初にストリームはunwrapを呼び出して、ストリームにエラーが有った場合はプログラムを停止することから始めている。
エラーがなければプログラムはメッセージを出力する。
クライアントがサーバーに接続する際にincomingメソッドからエラーを受け取る可能性がある理由は、実際には接続を走査していないから。
代わりに接続の試行を走査している。接続は多くの理由で失敗する可能性があり、そのうちの多くはOS特有。
例を上げれば多くのOSにはサポートできる同時に開いた接続数に上限がある。開かれた接続の一部が閉じられるまでその上限数を超えた接続の試行はエラーになる。

現在の実装ではサーバがデータを返してこないのでブラウザではエラーが出るが、メッセージは出ているので接続ができていることを確認できる。
一回のブラウザリクエストで複数のメッセージが出力されるのは、ブラウザがサーバに何度も接続を試みているという可能性があるが、理由は定かではない。

streamがスコープを抜け、ループの最後でドロップされると、接続はdrop実装の一部として閉じられる。
ブラウザは再試行することで閉じられた接続を扱うことがある。問題が一時的なものである可能性があるため。
重要な要素はTCP接続へのハンドルを得ることに成功したということ。


ブラウザからリクエストを読み取る機能を実装する。
まず接続を得て、それから接続に対してなんらかの行動を行う責任を分離するために、接続を処理する新しい関数を作成する。
新しいhandle_connection関数において、TCPストリームからデータを読み取り、ブラウザからデータが送られていることを確認できるように端末に出力させる。

std::io::preludeをスコープに導入して、ストリームから読み書きさせてくれる特定のトレイトにアクセスできるようにしている。
先程は接続を確立したというメッセージを出力していたが、今回はhandle_connection関数を呼び出し、streamを渡している。

handle_connection関数においてstream引数を可変にしたが、理由はTcpStreamインスタンスが内部で返すデータを追いかけているから。
要求した以上のデータを読み取り、次回データを要求したときのためにそのデータを保存する可能性がある。
故に、内部の状態が変化する可能性があるので、mutにする必要がある。

次にストリームから読み取りを2つの手順で行っていく。まずスタックに読み取ったデータを保持するbufferを宣言する。
今回はバッファーのサイズを1024バイトにした。今回の目的を達成するには十分な大きさ。
このバッファーをstream.readに渡し、これがTcpStreamからバイトを読み取ってバッファーに置く。

2番めにバッファーのバイトを文字列に変換し、その文字列を出力する。
String::from_utf8_lossy関数は&[u8]を取り、Stringを生成する。名前のlossyの部分は、
無効なUTF-8シーケンスに遭遇したときの関数の振る舞いを示唆している。
無効なシーケンスをU+FFFD REPLACEMENT CHARACTERで置き換える。
バッファーとして1024バイトの領域を用意しているが、リクエストデータは1024バイト存在しないことがほとんどなので、
変数bufferの後ろ部分が産められないまま放置されるため、置換された文字が表示されることがある。


今回の実行結果はこんな感じになる。

Request: GET / HTTP/1.1
Host: 127.0.0.1:7878
Connection: keep-alive
sec-ch-ua: " Not;A Brand";v="99", "Google Chrome";v="91", "Chromium";v="91"
sec-ch-ua-mobile: ?0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: none
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Accept-Encoding: gzip, deflate, br
Accept-Language: ja,en-US;q=0.9,en;q=0.8


HTTPはテキストベースのプロトコルで、1つの要求は以下のフォーマットに則っている。
Method Request-URI HTTP-Version CRLF
headers CRLF
message-body

一行目はクライアントが要求しているものが何なのかについての情報を保持するリクエスト行。
リクエスト行の最初の部分は使用されているGETやPOSTなどのメソッドを示し、
これはどのようにクライアントがこの要求を行っているかを記述する。クライアントはGETリクエストを使用している。

リクエスト業の次の部分は/で、これはクライアントが要求しているURI(Uniform Resource Identifier)を示している。
URIはほぼURL(Uniform Resource Locator)と同じだが、完全に同じではない。
HTTPの規格はURIという用語を使用している。

※URLはインターネット上に存在するファイルの場所を示すもので、Web上の住所に当たる。
　URIはインターネット上に素材するあらゆるファイルを識別する総称。URLはURIの一部。
　Web上の名前にあたるURNと合わせてURIと呼ばれている。

最後の部分はクライアントが使用しているHTTPのバージョンで、それからリクエスト行はCRLFで終了する。
CRLFにより、リクエスト行がリクエストデータの残りと区別される。CRLFを出力すると、\r\nではなく新しい行が開始されることに注意。

今回のリクエストは、
GETがメソッド、/が要求URI、HTTP/1.1がバージョンになっている。


クライアントのリクエストに対する返答としてデータの送信を実装していく。
レスポンスは以下のようなフォーマットになっている。

HTTP-Version Status-Code Reason-Phrase CRLF
headers CRLF
message-body

最初の行はレスポンスで使用されるHTTPバージョン、リクエストの結果を要約する数値ステータスコード。
そしてステータスコードのテキスト記述を提供する理由句を含むステータス行。
CRLFシーケンスのあとに任意のヘッダ、別のCRLFシーケンス、そしてレスポンスの本体が続く。

例えばHTTPバージョン1.1、ステータスコード200、OKフレーズ、ヘッダと本体なしのレスポンスは以下の通り。
HTTP/1.1 200 OK\r\n\r\n

ステータスコード200は一般的な成功のレスポンス。
これを成功したリクエストの返答としてストリームに書き込んでいく。

成功したメッセージのデータを保持するresponse変数を定義していて、responseに対してas_bytesを呼び出し、
文字列データをバイトに変換する。streamのwriteメソッドは&[u8]を取り、接続に直接そのバイトを送信する。
write処理は失敗することもあるので、以前のようにエラーの結果にはunwrapを使用する。
実際のアプリではエラー処理をきちんと追加してね。
最後にflush関数はバイトが全て接続に書き込まれるまでプログラムが継続するのを防ぐ。
TcpStreamは内部にバッファーを保持して、もととなるOSへの呼び出しを最小化する。


次はsrcの親ディレクトリに置いておいたhello.htmlをレスポンスとして返すようにしていく。
まずは標準ライブラリのFileをスコープに導入し、ファイルを開いて中身を読み込んでいる。
次に、format!でファイルの中身を成功したレスポンスの本体として追記している。

現時点ではbuffer内のリクエストデータは無視して、無条件でHTMLファイルの中身を送り返しているだけ。
これはつまり、ブラウザで127.0.0.1:7878/somethingをリクエストしても、同じHTMLレスポンスが得られるということ。
次はリクエストに基づいてレスポンスをカスタマイズし、/への合法なリクエストに対してのみHTMLファイルを送り返すようにしていく。

まず/リクエストに対応するデータをget変数に
let get = b"GET / HTTP/1.1\r\n";
とハードコードしている。生のバイトをバッファーに読み込んでいるので、b""というバイト文字列記法を中身のデータの先頭に追記することで、
getをバイト文字列に変換している。そしてbufferがgetのバイトから始まっているかを確認している。
もしそうならば/への合法的なリクエストを受け取ったことを意味し、これがHTMLファイルの中身を返すifブロックで扱う成功した場合になる。

bufferがgetのバイトで始まらないのであれば他のリクエストに受け取ったことになり、elseブロックでの処理に入る。


現状ではサーバはリクエストを順番に処理している。つまり、最初の接続が処理し終わるまで2番めの接続は処理しない。
サーバの受け付けるリクエストの量が増えるほど、この連続的な実行は最適ではなくなる。
サーバが処理するのに長い時間がかかるリクエストを受け付けたら、このリクエスト自体は迅速に処理できても、
続くリクエストは長いリクエストが完了するまで待たなければならなくなる。

use std::thread;
use std::time::Duration;
// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        thread::sleep(Duration::from_secs(5));
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };

    // --snip--
}

例えばこのコードで/sleepに接続しながら/に接続しようとすると、/が待たされるのを確認できる。

この問題を解決するために、多くのリクエストが遅いリクエストの背後に回ってしまうのを回避するようにウェブサーバが動く方法を変える方法は複数ある。
ここではスレッドプールを実装する。

スレッドプールは待機し、タスクを処理する準備のできた一塊の大量に生成されたスレッド。
プログラムが新しいタスクを受け取ったら、プールのスレッドのどれかをタスクにあてがい、そのスレッドがそのタスクを処理する。
プールの残りのスレッドは最初のスレッドが処理中にやってくる他のあらゆるタスクを扱うために利用可能。
最初のスレッドがタスクの処理を完了したら、アイドル状態のスレッドプールに戻り、新しいタスクを処理する準備ができる。
スレッドプールにより、並行で接続を処理でき、サーバのスループットを向上させる。

プール内のスレッド数は小さい数字に制限し、DoS攻撃から保護する。リクエストが来るたびに新しいスレッドを生成させると、
大量のリクエストをサーバに送り、サーバのリソースを使い尽くしリクエストの処理を停止に追い込むことができてしまう。

無制限にスレッドを大量生産するのではなく、プールに固定された数のスレッドを待機させる。リクエストが来るたびに、
処理するためにプールに送られる。プールはやってくるリクエストのキューを管理する。
プールの各スレッドがこのキューからリクエストを取り出し、リクエストを処理し、別のリクエストをキューに要求する。
この設計により、Nリクエストを並行して処理でき、ここで言うNはスレッド数のこと。
各スレッドが実行に時間のかかるリクエストに応答していたら、続くリクエストはキュー内で待機させられることもあるが、
その地点に到達する前に扱える時間のかかるリクエスト数を増加させれば良い。
この他にWebサーバのスループットを向上させる方法としては、fork/joinモデルと、シングルスレッドの非同期I/Oモデルが挙げられる。